{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tools for text processing\n",
    "\n",
    "What are the most frequent words in Herman Melville's novel, Moby Dick, and how often do they occur?\n",
    "\n",
    "In this notebook, we'll scrape the novel Moby Dick from the website Project Gutenberg (which contains a large corpus of books) using the Python package requests. Then we'll extract words from this web data using BeautifulSoup. Finally, we'll dive into analyzing the distribution of words using the Natural Language ToolKit (nltk) and Counter.\n",
    "\n",
    "The Data Science pipeline we'll build in this notebook can be used to visualize the word frequency distributions of any novel that you can find on Project Gutenberg. The natural language processing tools used here apply to much of the data that data scientists encounter as a vast proportion of the world's data is unstructured data and includes a great deal of text.\n",
    "\n",
    "Let's start by loading in the three main Python packages we are going to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "\n",
      "<!DOCTYPE html\n",
      "   PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n",
      "   \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\" >\n",
      "\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
      "  <head>\n",
      "    <title>\n",
      "      Moby Dick; Or the Whale, by Herman Melville\n",
      "    </title>\n",
      "    <style type=\"text/css\" xml:space=\"preserve\">\n",
      "\n",
      "    body { background:#faebd0; color:black; margin-left:15%; margin-right:15%; text-align:justify }\n",
      "    P { text-indent: 1em; margin-top: .25em; margin-bottom: .25em; }\n",
      "    H1,H2,H3,H4,H5,H6 { text-align: center; margin-left: 15%; margin-right: 15%; }\n",
      "    hr  { width: 50%; text-align: center;}\n",
      "    .foot { margin-left: 20%; margin-right: 20%; text-align: justify; text-indent: -3em; font-size: 90%; }\n",
      "    blockquote {font-size: 100%; margin-left: 0%; margin-right: 0%;}\n",
      "    .mynote    {background-color: #DDE; color: #000; padding: .5em; margin-left: 10%; margin-right: 10%; font-family: sans-serif; font-size: 95%;}\n",
      "    .toc       { margin-left: 10%; margin-bottom: .75em;}\n",
      "    .toc2      { margin-left: 20%;}\n",
      "    div.fig    { display:block; margin:0 auto; text-align:center; }\n",
      "    div.middle { margin-left: 20%; margin-right: 20%; text-align: justify; }\n",
      "    .figleft   {float: left; margin-left: 0%; margin-right: 1%;}\n",
      "    .figright  {float: right; margin-right: 0%; margin-left: 1%;}\n",
      "    .pagenum   {display:inline; font-size: 70%; font-style:normal;\n",
      "               margin: 0; padding: 0; position: absolute; right: 1%;\n",
      "               text-align: right;}\n",
      "    pre        { font-family: times new roman; font-size: 100%; margin-left: 10%;}\n",
      "\n",
      "    table      {margin-left: 10%;}\n",
      "\n",
      "a:link {color:blue;\n",
      "\t\ttext-decoration:none}\n",
      "link {color:blue;\n",
      "\t\ttext-decoration:none}\n",
      "a:visited {color:blue;\n",
      "\t\ttext-decoration:none}\n",
      "a:hover {color:red}\n",
      "\n",
      "</style>\n",
      "  </head>\n",
      "  <body>\n",
      "<pre xml:space=\"preserve\">\n",
      "\n",
      "The Project Gutenberg EBook of Moby Dick; or The Whale, by Herman Melville\n",
      "\n",
      "This eBook is for the use of anyone anywh\n"
     ]
    }
   ],
   "source": [
    "# Getting the Moby Dick HTML \n",
    "r = requests.get('https://s3.amazonaws.com/assets.datacamp.com/production/project_147/datasets/2701-h.htm')\n",
    "\n",
    "# Setting the correct text encoding of the HTML page\n",
    "r.encoding = 'utf-8'\n",
    "\n",
    "# Extracting the HTML from the request object\n",
    "html = r.text\n",
    "\n",
    "# Printing the first 2000 characters in html\n",
    "# ... YOUR CODE FOR TASK 3 ...\n",
    "print(html[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the text from the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent me\n",
      "      from deliberately stepping into the street, and methodically knocking\n",
      "      people’s hats off—then, I account it high time to get to sea as soon\n",
      "      as I can. This is my substitute for pistol and ball. With a philosophical\n",
      "      flourish Cato throws himself upon his sword; I quietly take to the ship.\n",
      "      There is nothing surprising in this. If they but knew it, almost all men\n",
      "      in their degree, some time or other, cherish very nearly the same feelings\n",
      "      towards the ocean with me.\n",
      "    \n",
      "\n",
      "      There now is your insular city of the Manhattoes, belted round by wharves\n",
      "      as Indian isles by coral reefs—commerce surrounds it with her surf.\n",
      "      Right and left, the streets take you waterward. Its extreme downtown is\n",
      "      the battery, where that noble mole is washed by waves, and cooled by\n",
      "      breezes, which a few hours previous were out of sight of land. Look at the\n",
      "      crowds of water-gazers there.\n",
      "    \n",
      "\n",
      "      Circumambulate the city of a dreamy Sabbath afternoon. Go from Corlears\n",
      "      Hook to Coenties Slip, and from thence, by Whitehall, northward. What do\n",
      "      you see?—Posted like silent sentinels all around the town, stand\n",
      "      thousands upon thousands of mortal men fixed in ocean reveries. Some\n",
      "      leaning against the spiles; some seated upon the pier-heads; some looking\n",
      "      over the bulwarks of ships from China; some high aloft in the rigging, as\n",
      "      if striving to get a still better seaward peep. But these are all\n",
      "      landsmen; of week days pent up in lath and plaster—tied to counters,\n",
      "      nailed to benches, clinched to desks. How then is this? Are the green\n",
      "      fields gone? What do they here?\n",
      "    \n",
      "\n",
      "      But look! here come more crowds, pacing straight for the water, and\n",
      "      seemingly bound for a dive. Strange! Nothing will content them but the\n",
      "      extremest limit of the land; loitering under the shady lee of yonder\n",
      "      warehouses will not suffice. No. They must get just as nigh th\n"
     ]
    }
   ],
   "source": [
    "# Creating a BeautifulSoup object from the HTML\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# Getting the text out of the soup\n",
    "text = soup.text\n",
    "\n",
    "# Printing out text between characters 32000 and 34000\n",
    "# ... YOUR CODE FOR TASK 3 ...\n",
    "print(text[32000:34000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tokenizer\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\b\\w+\\b')\n",
    "\n",
    "# Tokenizing the text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "# Printing out the first 8 words / tokens \n",
    "# ... YOUR CODE FOR TASK 4 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the words lowercase¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moby', 'dick', 'or', 'the', 'whale', 'by', 'herman', 'melville']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list called words containing all tokens transformed to lower-case\n",
    "# ... YOUR CODE FOR TASK 5 ...\n",
    "words = []\n",
    "for word in tokens:\n",
    "    words.append(word.lower())\n",
    "# Printing out the first 8 words / tokens \n",
    "# ... YOUR CODE FOR TASK 5 ...\n",
    "words[:8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/janderson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Getting the English stop words from nltk\n",
    "nltk.download('stopwords')\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "# Printing out the first eight stop words\n",
    "# ... YOUR CODE FOR TASK 6 ...\n",
    "print(sw[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words in Moby Dick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moby', 'dick', 'whale', 'herman', 'melville']\n"
     ]
    }
   ],
   "source": [
    "# Create a list words_ns containing all words that are in words but not in sw\n",
    "# ... YOUR CODE FOR TASK 7 ...\n",
    "words_ns = [word for word in words if word not in sw]\n",
    "\n",
    "# Printing the first 5 words_ns to check that stop words are gone\n",
    "# ... YOUR CODE FOR TASK 7 ...\n",
    "print(words_ns[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have the answer\n",
    "\n",
    "Our original question was:\n",
    "\n",
    "What are the most frequent words in Herman Melville's novel Moby Dick and how often do they occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whale', 1246), ('one', 925), ('like', 647), ('upon', 568), ('man', 527), ('ship', 519), ('ahab', 517), ('ye', 473), ('sea', 455), ('old', 452)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Counter object from our processed list of words\n",
    "count = Counter(words_ns)\n",
    "\n",
    "# Store 10 most common words and their counts as top_ten\n",
    "top_ten = count.most_common(10)\n",
    "\n",
    "# Print the top ten words and their counts\n",
    "print(top_ten)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
